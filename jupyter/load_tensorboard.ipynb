{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (2.5.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (3.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (58.1.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (1.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (1.22.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorboard) (1.35.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n",
      "Installing collected packages: libclang, keras, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, absl-py, pandas, tensorboard, tensorflow\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-22.9.24 gast-0.4.0 google-pasta-0.2.0 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 opt-einsum-3.3.0 pandas-1.5.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wrapt-1.14.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/jerrit/QuantPerf/venv/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mThe tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 19:12:14.209390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-10 19:12:14.333160: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-10 19:12:14.333177: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-10 19:12:14.364310: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-10 19:12:15.024739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-10 19:12:15.024824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-10 19:12:15.024833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorboard tensorflow pandas\n",
    "\n",
    "\"\"\"\n",
    "If tensorboard is not installed (or other dependencies, such as tensorflow and pandas),\n",
    "uncomment the command in top and re-run. This needs only to be run once in a Jupyter kernel.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-65214641f00e479\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-65214641f00e479\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Change the LOG_DIR argument to point to the correct directory, you may want to use an\n",
    "absolute path if you run into issues.\n",
    "\"\"\"\n",
    "%tensorboard --logdir ./logging/0/vit_mnist_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def logs_to_pandas(path: str) -> pd.DataFrame:\n",
    "    \"\"\"convert single tensorflow log file to pandas DataFrame\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to tensorflow log file\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        converted dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    runlog_data = pd.DataFrame({\"metric\": [], \"value\": [], \"step\": [], \"wall_time\": []})\n",
    "    try:\n",
    "        event_acc = summary_iterator(path)\n",
    "        for event in list(event_acc)[1:]:\n",
    "            step, wall_time = event.step, pd.to_datetime(event.wall_time, unit='s')\n",
    "            simple_extractor = [{\"metric\": v.tag, \"value\": v.simple_value, \"step\": step, 'wall_time': wall_time} for v in event.summary.value]\n",
    "            event_r = pd.DataFrame(simple_extractor)\n",
    "            runlog_data = pd.concat([runlog_data, event_r])\n",
    "    # Dirty catch of DataLossError\n",
    "    except Exception as e:\n",
    "        print(\"Event file possibly corrupt: {}\".format(path))\n",
    "        print(e)\n",
    "    return runlog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages/tensorflow/python/summary/summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>step</th>\n",
       "      <th>wall_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.211613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-10 16:16:44.471569920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>92.709999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-10 16:16:44.471712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.137676</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-10-10 16:18:52.216119040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>96.099998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-10-10 16:18:52.216292864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.113547</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-10-10 16:20:58.499702016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>96.089996</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-10-10 16:20:58.499828992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.103963</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-10-10 16:23:05.026704640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>96.989998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-10-10 16:23:05.026844416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.082212</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-10 16:25:12.294663936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.449997</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-10 16:25:12.294792960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.074630</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-10-10 16:27:19.496970752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.540001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-10-10 16:27:19.497125632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.066825</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-10-10 16:29:26.625154304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.160004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-10-10 16:29:26.625302272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022-10-10 16:31:35.010835200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.800003</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022-10-10 16:31:35.010958592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.057223</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-10-10 16:33:41.997623808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-10-10 16:33:41.997761792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.055659</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-10-10 16:35:50.001763584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.669998</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-10-10 16:35:50.001902336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.043097</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2022-10-10 16:37:57.386013696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.709999</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2022-10-10 16:37:57.386184960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.047246</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2022-10-10 16:40:04.810410240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2022-10-10 16:40:04.810535680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2022-10-10 16:42:11.788609536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.849998</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2022-10-10 16:42:11.788738816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2022-10-10 16:44:18.408947968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.559998</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2022-10-10 16:44:18.409124096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-10-10 16:46:26.722095360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.739998</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-10-10 16:46:26.722255360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2022-10-10 16:48:33.718629888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.830002</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2022-10-10 16:48:33.718784768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.045754</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2022-10-10 16:50:40.628909312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.059998</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2022-10-10 16:50:40.629028864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.037208</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-10-10 16:52:47.822538752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.959999</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-10-10 16:52:47.822662912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.026280</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2022-10-10 16:54:54.416340480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.139999</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2022-10-10 16:54:54.416470272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2022-10-10 16:57:01.893475072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.180000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2022-10-10 16:57:01.893627136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.024352</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2022-10-10 16:59:08.919820544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2022-10-10 16:59:08.919953152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.031502</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-10-10 17:01:16.010617344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.190002</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-10-10 17:01:16.010730240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.027928</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2022-10-10 17:03:22.723319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.040001</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2022-10-10 17:03:22.723449856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2022-10-10 17:05:30.295873536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.989998</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2022-10-10 17:05:30.296021760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2022-10-10 17:07:38.192391936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    metric      value  step                     wall_time\n",
       "0  training loss per epoch   0.211613   1.0 2022-10-10 16:16:44.471569920\n",
       "0       accuracy per epoch  92.709999   1.0 2022-10-10 16:16:44.471712000\n",
       "0  training loss per epoch   0.137676   2.0 2022-10-10 16:18:52.216119040\n",
       "0       accuracy per epoch  96.099998   2.0 2022-10-10 16:18:52.216292864\n",
       "0  training loss per epoch   0.113547   3.0 2022-10-10 16:20:58.499702016\n",
       "0       accuracy per epoch  96.089996   3.0 2022-10-10 16:20:58.499828992\n",
       "0  training loss per epoch   0.103963   4.0 2022-10-10 16:23:05.026704640\n",
       "0       accuracy per epoch  96.989998   4.0 2022-10-10 16:23:05.026844416\n",
       "0  training loss per epoch   0.082212   5.0 2022-10-10 16:25:12.294663936\n",
       "0       accuracy per epoch  97.449997   5.0 2022-10-10 16:25:12.294792960\n",
       "0  training loss per epoch   0.074630   6.0 2022-10-10 16:27:19.496970752\n",
       "0       accuracy per epoch  97.540001   6.0 2022-10-10 16:27:19.497125632\n",
       "0  training loss per epoch   0.066825   7.0 2022-10-10 16:29:26.625154304\n",
       "0       accuracy per epoch  97.160004   7.0 2022-10-10 16:29:26.625302272\n",
       "0  training loss per epoch   0.055468   8.0 2022-10-10 16:31:35.010835200\n",
       "0       accuracy per epoch  97.800003   8.0 2022-10-10 16:31:35.010958592\n",
       "0  training loss per epoch   0.057223   9.0 2022-10-10 16:33:41.997623808\n",
       "0       accuracy per epoch  97.699997   9.0 2022-10-10 16:33:41.997761792\n",
       "0  training loss per epoch   0.055659  10.0 2022-10-10 16:35:50.001763584\n",
       "0       accuracy per epoch  97.669998  10.0 2022-10-10 16:35:50.001902336\n",
       "0  training loss per epoch   0.043097  11.0 2022-10-10 16:37:57.386013696\n",
       "0       accuracy per epoch  97.709999  11.0 2022-10-10 16:37:57.386184960\n",
       "0  training loss per epoch   0.047246  12.0 2022-10-10 16:40:04.810410240\n",
       "0       accuracy per epoch  97.400002  12.0 2022-10-10 16:40:04.810535680\n",
       "0  training loss per epoch   0.044686  13.0 2022-10-10 16:42:11.788609536\n",
       "0       accuracy per epoch  97.849998  13.0 2022-10-10 16:42:11.788738816\n",
       "0  training loss per epoch   0.037523  14.0 2022-10-10 16:44:18.408947968\n",
       "0       accuracy per epoch  97.559998  14.0 2022-10-10 16:44:18.409124096\n",
       "0  training loss per epoch   0.033800  15.0 2022-10-10 16:46:26.722095360\n",
       "0       accuracy per epoch  97.739998  15.0 2022-10-10 16:46:26.722255360\n",
       "0  training loss per epoch   0.037088  16.0 2022-10-10 16:48:33.718629888\n",
       "0       accuracy per epoch  97.830002  16.0 2022-10-10 16:48:33.718784768\n",
       "0  training loss per epoch   0.045754  17.0 2022-10-10 16:50:40.628909312\n",
       "0       accuracy per epoch  98.059998  17.0 2022-10-10 16:50:40.629028864\n",
       "0  training loss per epoch   0.037208  18.0 2022-10-10 16:52:47.822538752\n",
       "0       accuracy per epoch  97.959999  18.0 2022-10-10 16:52:47.822662912\n",
       "0  training loss per epoch   0.026280  19.0 2022-10-10 16:54:54.416340480\n",
       "0       accuracy per epoch  98.139999  19.0 2022-10-10 16:54:54.416470272\n",
       "0  training loss per epoch   0.036465  20.0 2022-10-10 16:57:01.893475072\n",
       "0       accuracy per epoch  98.180000  20.0 2022-10-10 16:57:01.893627136\n",
       "0  training loss per epoch   0.024352  21.0 2022-10-10 16:59:08.919820544\n",
       "0       accuracy per epoch  98.000000  21.0 2022-10-10 16:59:08.919953152\n",
       "0  training loss per epoch   0.031502  22.0 2022-10-10 17:01:16.010617344\n",
       "0       accuracy per epoch  98.190002  22.0 2022-10-10 17:01:16.010730240\n",
       "0  training loss per epoch   0.027928  23.0 2022-10-10 17:03:22.723319808\n",
       "0       accuracy per epoch  98.040001  23.0 2022-10-10 17:03:22.723449856\n",
       "0  training loss per epoch   0.042365  24.0 2022-10-10 17:05:30.295873536\n",
       "0       accuracy per epoch  97.989998  24.0 2022-10-10 17:05:30.296021760\n",
       "0  training loss per epoch   0.021418  25.0 2022-10-10 17:07:38.192391936"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./logging/0/vit_mnist_1/0/Nets.vit_mnist_Dataset.mnist_rgb/events.out.tfevents.1665418474.trainjob-ccc6572c-3f39-4df8-9175-106a0b8d44a7-master-0.1.0\"\n",
    "logs_to_pandas(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
