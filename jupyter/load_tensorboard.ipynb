{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 11:10:57.267821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-11 11:10:57.385045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-11 11:10:57.385095: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-11 11:10:57.413887: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-11 11:10:58.059877: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-11 11:10:58.059955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-11 11:10:58.059964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorboard tensorflow pandas\n",
    "\n",
    "\"\"\"\n",
    "If tensorboard is not installed (or other dependencies, such as tensorflow and pandas),\n",
    "uncomment the command in top and re-run. This needs only to be run once in a Jupyter kernel.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14746), started 15:59:20 ago. (Use '!kill 14746' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7dfbe241a112d83a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7dfbe241a112d83a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Change the LOG_DIR argument to point to the correct directory, you may want to use an\n",
    "absolute path if you run into issues.\n",
    "\"\"\"\n",
    "%tensorboard --logdir ./logging/0/vit_mnist_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def logs_to_pandas(path: str) -> pd.DataFrame:\n",
    "    \"\"\"convert single tensorflow log file to pandas DataFrame\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to tensorflow log file\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        converted dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    runlog_data = pd.DataFrame({\"metric\": [], \"value\": [], \"step\": [], \"wall_time\": []})\n",
    "    try:\n",
    "        event_acc = summary_iterator(path)\n",
    "        for event in list(event_acc)[1:]:\n",
    "            step, wall_time = event.step, pd.to_datetime(event.wall_time, unit='s')\n",
    "            simple_extractor = [{\"metric\": v.tag, \"value\": v.simple_value, \"step\": step, 'wall_time': wall_time} for v in event.summary.value]\n",
    "            event_r = pd.DataFrame(simple_extractor)\n",
    "            runlog_data = pd.concat([runlog_data, event_r])\n",
    "    # Dirty catch of DataLossError\n",
    "    except Exception as e:\n",
    "        print(\"Event file possibly corrupt: {}\".format(path))\n",
    "        print(e)\n",
    "    return runlog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jerrit/QuantPerf/venv/lib/python3.9/site-packages/tensorflow/python/summary/summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>step</th>\n",
       "      <th>wall_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.211613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-10 16:16:44.471569920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>92.709999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-10 16:16:44.471712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.137676</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-10-10 16:18:52.216119040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>96.099998</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-10-10 16:18:52.216292864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.113547</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-10-10 16:20:58.499702016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>96.089996</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-10-10 16:20:58.499828992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.103963</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-10-10 16:23:05.026704640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>96.989998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-10-10 16:23:05.026844416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.082212</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-10 16:25:12.294663936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.449997</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-10 16:25:12.294792960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.074630</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-10-10 16:27:19.496970752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.540001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-10-10 16:27:19.497125632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.066825</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-10-10 16:29:26.625154304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.160004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-10-10 16:29:26.625302272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022-10-10 16:31:35.010835200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.800003</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022-10-10 16:31:35.010958592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.057223</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-10-10 16:33:41.997623808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-10-10 16:33:41.997761792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.055659</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-10-10 16:35:50.001763584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.669998</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-10-10 16:35:50.001902336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.043097</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2022-10-10 16:37:57.386013696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.709999</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2022-10-10 16:37:57.386184960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.047246</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2022-10-10 16:40:04.810410240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2022-10-10 16:40:04.810535680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.044686</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2022-10-10 16:42:11.788609536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.849998</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2022-10-10 16:42:11.788738816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2022-10-10 16:44:18.408947968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.559998</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2022-10-10 16:44:18.409124096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-10-10 16:46:26.722095360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.739998</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-10-10 16:46:26.722255360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2022-10-10 16:48:33.718629888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.830002</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2022-10-10 16:48:33.718784768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.045754</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2022-10-10 16:50:40.628909312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.059998</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2022-10-10 16:50:40.629028864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.037208</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-10-10 16:52:47.822538752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.959999</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-10-10 16:52:47.822662912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.026280</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2022-10-10 16:54:54.416340480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.139999</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2022-10-10 16:54:54.416470272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2022-10-10 16:57:01.893475072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.180000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2022-10-10 16:57:01.893627136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.024352</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2022-10-10 16:59:08.919820544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2022-10-10 16:59:08.919953152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.031502</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-10-10 17:01:16.010617344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.190002</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-10-10 17:01:16.010730240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.027928</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2022-10-10 17:03:22.723319808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>98.040001</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2022-10-10 17:03:22.723449856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2022-10-10 17:05:30.295873536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy per epoch</td>\n",
       "      <td>97.989998</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2022-10-10 17:05:30.296021760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training loss per epoch</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2022-10-10 17:07:38.192391936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    metric      value  step                     wall_time\n",
       "0  training loss per epoch   0.211613   1.0 2022-10-10 16:16:44.471569920\n",
       "0       accuracy per epoch  92.709999   1.0 2022-10-10 16:16:44.471712000\n",
       "0  training loss per epoch   0.137676   2.0 2022-10-10 16:18:52.216119040\n",
       "0       accuracy per epoch  96.099998   2.0 2022-10-10 16:18:52.216292864\n",
       "0  training loss per epoch   0.113547   3.0 2022-10-10 16:20:58.499702016\n",
       "0       accuracy per epoch  96.089996   3.0 2022-10-10 16:20:58.499828992\n",
       "0  training loss per epoch   0.103963   4.0 2022-10-10 16:23:05.026704640\n",
       "0       accuracy per epoch  96.989998   4.0 2022-10-10 16:23:05.026844416\n",
       "0  training loss per epoch   0.082212   5.0 2022-10-10 16:25:12.294663936\n",
       "0       accuracy per epoch  97.449997   5.0 2022-10-10 16:25:12.294792960\n",
       "0  training loss per epoch   0.074630   6.0 2022-10-10 16:27:19.496970752\n",
       "0       accuracy per epoch  97.540001   6.0 2022-10-10 16:27:19.497125632\n",
       "0  training loss per epoch   0.066825   7.0 2022-10-10 16:29:26.625154304\n",
       "0       accuracy per epoch  97.160004   7.0 2022-10-10 16:29:26.625302272\n",
       "0  training loss per epoch   0.055468   8.0 2022-10-10 16:31:35.010835200\n",
       "0       accuracy per epoch  97.800003   8.0 2022-10-10 16:31:35.010958592\n",
       "0  training loss per epoch   0.057223   9.0 2022-10-10 16:33:41.997623808\n",
       "0       accuracy per epoch  97.699997   9.0 2022-10-10 16:33:41.997761792\n",
       "0  training loss per epoch   0.055659  10.0 2022-10-10 16:35:50.001763584\n",
       "0       accuracy per epoch  97.669998  10.0 2022-10-10 16:35:50.001902336\n",
       "0  training loss per epoch   0.043097  11.0 2022-10-10 16:37:57.386013696\n",
       "0       accuracy per epoch  97.709999  11.0 2022-10-10 16:37:57.386184960\n",
       "0  training loss per epoch   0.047246  12.0 2022-10-10 16:40:04.810410240\n",
       "0       accuracy per epoch  97.400002  12.0 2022-10-10 16:40:04.810535680\n",
       "0  training loss per epoch   0.044686  13.0 2022-10-10 16:42:11.788609536\n",
       "0       accuracy per epoch  97.849998  13.0 2022-10-10 16:42:11.788738816\n",
       "0  training loss per epoch   0.037523  14.0 2022-10-10 16:44:18.408947968\n",
       "0       accuracy per epoch  97.559998  14.0 2022-10-10 16:44:18.409124096\n",
       "0  training loss per epoch   0.033800  15.0 2022-10-10 16:46:26.722095360\n",
       "0       accuracy per epoch  97.739998  15.0 2022-10-10 16:46:26.722255360\n",
       "0  training loss per epoch   0.037088  16.0 2022-10-10 16:48:33.718629888\n",
       "0       accuracy per epoch  97.830002  16.0 2022-10-10 16:48:33.718784768\n",
       "0  training loss per epoch   0.045754  17.0 2022-10-10 16:50:40.628909312\n",
       "0       accuracy per epoch  98.059998  17.0 2022-10-10 16:50:40.629028864\n",
       "0  training loss per epoch   0.037208  18.0 2022-10-10 16:52:47.822538752\n",
       "0       accuracy per epoch  97.959999  18.0 2022-10-10 16:52:47.822662912\n",
       "0  training loss per epoch   0.026280  19.0 2022-10-10 16:54:54.416340480\n",
       "0       accuracy per epoch  98.139999  19.0 2022-10-10 16:54:54.416470272\n",
       "0  training loss per epoch   0.036465  20.0 2022-10-10 16:57:01.893475072\n",
       "0       accuracy per epoch  98.180000  20.0 2022-10-10 16:57:01.893627136\n",
       "0  training loss per epoch   0.024352  21.0 2022-10-10 16:59:08.919820544\n",
       "0       accuracy per epoch  98.000000  21.0 2022-10-10 16:59:08.919953152\n",
       "0  training loss per epoch   0.031502  22.0 2022-10-10 17:01:16.010617344\n",
       "0       accuracy per epoch  98.190002  22.0 2022-10-10 17:01:16.010730240\n",
       "0  training loss per epoch   0.027928  23.0 2022-10-10 17:03:22.723319808\n",
       "0       accuracy per epoch  98.040001  23.0 2022-10-10 17:03:22.723449856\n",
       "0  training loss per epoch   0.042365  24.0 2022-10-10 17:05:30.295873536\n",
       "0       accuracy per epoch  97.989998  24.0 2022-10-10 17:05:30.296021760\n",
       "0  training loss per epoch   0.021418  25.0 2022-10-10 17:07:38.192391936"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./logging/0/vit_mnist_1/0/Nets.vit_mnist_Dataset.mnist_rgb/events.out.tfevents.1665418474.trainjob-ccc6572c-3f39-4df8-9175-106a0b8d44a7-master-0.1.0\"\n",
    "logs_to_pandas(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
